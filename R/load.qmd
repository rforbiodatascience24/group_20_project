---
title: "Lab 6 Assignement: Group 20"
author: Antoine Andréoletti, Olivier Gaufrès, Amy Surry, Lea Skytthe, Trine Søgaard
format:
  html:
    embed-resources: true
editor: visual
---

# Data

The data we are using in this exercise comes from a paper from Gravier et al. (2020) and is available here: <https://ftp.ebi.ac.uk/biostudies/fire/E-MTAB-/807/E-MTAB-12807/Files/40mayoicf_quant.sf>.

## Load Libraries

```{r}
#| message: False

library("tidyverse")
library("sf")
library("httr")
library("XML")
library("stringr")
```

## Import data

```{r}
#| message: False

base_url <- "https://ftp.ebi.ac.uk/biostudies/fire/E-MTAB-/807/E-MTAB-12807/Files/"

# Make an HTTP GET request
response <- GET(base_url)

# Parse the HTML content
html_doc <- htmlParse(content(response, as = "text"), asText = TRUE)

# Extract file links (adjust the XPath as needed)
file_links <- xpathSApply(html_doc, "//a/@href")
file_links <- data.frame(files = file_links)

count_files <- file_links |> 
  filter(str_ends(files, ".sf")) |> 
  pull(files)

metadata_files <- file_links |> 
  filter(str_ends(files, ".txt")) |> 
  pull(files)

# Importing each file and downloading it in the right folder
base <- "../data/_raw"

for (count_file in count_files) {
  file_path <- paste(base_url, count_file, 
                     sep = "")
  file <- read_tsv(file = file_path)
  new_file_name <- str_replace(count_file, ".sf", ".csv")
  new_file_path <- paste(base, "/count_data/", new_file_name,
                         sep = "")
  write_csv(file, file = new_file_path)
}

for (metadata_file in metadata_files) {
  file_path <- paste(base_url, metadata_file, 
                     sep = "")
  file <- read_tsv(file = file_path)
  new_file_name <- str_replace(metadata_file, ".txt", ".csv")
  new_file_path <- paste(base, "/metadata/", new_file_name,
                         sep = "")
  write_csv(file, file = new_file_path)
}
```
